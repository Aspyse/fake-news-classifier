{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ISWSyFpSrZbh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDrkoH9A1Wou"
      },
      "source": [
        "Press **Runtime>Run all** or **Ctrl+F9**, then paste the article in the text box below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISWSyFpSrZbh"
      },
      "source": [
        "# ***code*** (keep collapsed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J1NrBa0pr2B",
        "outputId": "eed4178a-5bfa-4d1a-93c7-32bc6b6953cf"
      },
      "source": [
        "import requests\n",
        "\n",
        "model_url_2 = \"https://drive.google.com/u/1/uc?id=1--MdsVFTdu8hTx-0Weh-TTAZG3Dcezc3&export=download\"\n",
        "model_url_3 = \"https://drive.google.com/u/1/uc?id=1HPFk_opoGgEAn-4FBgZjB33iZ9fEeMbH&export=download\"\n",
        "model_url_4 = \"https://drive.google.com/u/1/uc?id=1dgW6dspYatU2K6WqC97Pa7zTtRZ2tWye&export=download\"\n",
        "model_url_7 = \"https://drive.google.com/u/1/uc?id=1aMsvvYS7thijOOoakKm1yBssMjj9oVLA&export=download\"\n",
        "model_url_9 = \"https://drive.google.com/u/1/uc?id=1-27eLhJmXjtb4Tn-oNeEnZgmmC1RBjuL&export=download\"\n",
        "r = requests.get(model_url_9, allow_redirects=True)\n",
        "open(\"news-model.ftz\", 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2043718"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIlckGDtr25l"
      },
      "source": [
        "# taken from FastText sentiment analysis for text by Charles Malafosse\n",
        "import re\n",
        "import itertools\n",
        " \n",
        "def load_dict_contractions():\n",
        "    return {\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        }\n",
        " \n",
        "def strip_accents(text):\n",
        "    if 'ø' in text or  'Ø' in text:\n",
        "        #Do nothing when finding ø \n",
        "        return text   \n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return str(text)\n",
        " \n",
        "def text_cleaning_for_analysis(text):    \n",
        " \n",
        "    #Special case not handled previously.\n",
        "    text = text.replace('\\x92',\"'\")\n",
        " \n",
        "    #Removal of address\n",
        "    text = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
        " \n",
        "    #Removal of Punctuation\n",
        "    text = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", text).split())\n",
        " \n",
        "    #Lower case\n",
        "    text = text.lower()\n",
        " \n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        " \n",
        "    text = text.replace(\"’\",\"'\")\n",
        "    words = text.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    text = \" \".join(reformed)\n",
        " \n",
        "    # Standardizing words\n",
        "    text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\n",
        " \n",
        "    #Strip accents\n",
        "    text= strip_accents(text)\n",
        "    text = text.replace(\":\",\" \")\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    # DO NOT REMOVE STOP WORDS FOR SENTIMENT ANALYSIS - OR AT LEAST NOT NEGATIVE ONES\n",
        " \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgwn9yDXqad3",
        "outputId": "2de3ccff-70bc-447b-c833-c91d813091de"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "%cd fastText\n",
        "!sudo pip install .\n",
        "%cd ..\n",
        "\n",
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3854, done.\u001b[K\n",
            "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\n",
            "Receiving objects: 100% (3854/3854), 8.23 MiB | 30.08 MiB/s, done.\n",
            "Resolving deltas: 100% (2416/2416), done.\n",
            "/content/fastText\n",
            "Processing /content/fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (51.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3088705 sha256=8d9a70c061676f95de75925d890965a69185ca2047f5400a23b9b6c69fe7fe29\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hl4iqo_h/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu5fk9YgqgNs"
      },
      "source": [
        "model = fasttext.load_model(\"news-model.ftz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTA9yjiFrsAK"
      },
      "source": [
        "def predict_from_user():\n",
        "  input_text = input(\"Enter news for classification:\\n > \")\n",
        "  cleaned_text = text_cleaning_for_analysis(input_text)\n",
        "  prediction = model.predict(cleaned_text)\n",
        "  print(\"The text is predicted to be {} news.\".format(prediction[0][0][9:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4zpE-FvriM8"
      },
      "source": [
        "# ***ui*** (input text for classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3jr-0tSrhiG",
        "outputId": "7cb75983-f84c-44ed-ba42-53ddcaaca171"
      },
      "source": [
        "predict_from_user()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter news for classification:\n",
            " > The quick brown fox jumps over the lazy dog.\n",
            "The text is predicted to be fake news.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}